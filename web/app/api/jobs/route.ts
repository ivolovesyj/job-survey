import { NextResponse } from 'next/server'
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

// ============================================
// Jaro-Winkler ìœ ì‚¬ë„ ê³„ì‚° (ë¹„ìš© ì—†ëŠ” ìœ ì‚¬ë„ ë§¤ì¹­)
// ============================================

function jaroWinklerDistance(s1: string, s2: string): number {
  const len1 = s1.length
  const len2 = s2.length

  if (len1 === 0 && len2 === 0) return 1.0
  if (len1 === 0 || len2 === 0) return 0.0

  const matchWindow = Math.floor(Math.max(len1, len2) / 2) - 1
  const s1Matches = new Array(len1).fill(false)
  const s2Matches = new Array(len2).fill(false)

  let matches = 0
  let transpositions = 0

  // ë§¤ì¹­ ì°¾ê¸°
  for (let i = 0; i < len1; i++) {
    const start = Math.max(0, i - matchWindow)
    const end = Math.min(i + matchWindow + 1, len2)

    for (let j = start; j < end; j++) {
      if (s2Matches[j] || s1[i] !== s2[j]) continue
      s1Matches[i] = true
      s2Matches[j] = true
      matches++
      break
    }
  }

  if (matches === 0) return 0.0

  // ì „ì¹˜(transposition) ê³„ì‚°
  let k = 0
  for (let i = 0; i < len1; i++) {
    if (!s1Matches[i]) continue
    while (!s2Matches[k]) k++
    if (s1[i] !== s2[k]) transpositions++
    k++
  }

  // Jaro ìœ ì‚¬ë„
  const jaro = (matches / len1 + matches / len2 + (matches - transpositions / 2) / matches) / 3

  // ê³µí†µ ì ‘ë‘ì‚¬ ê¸¸ì´ (ìµœëŒ€ 4)
  let prefixLength = 0
  for (let i = 0; i < Math.min(len1, len2, 4); i++) {
    if (s1[i] === s2[i]) prefixLength++
    else break
  }

  // Jaro-Winkler ìœ ì‚¬ë„ (p=0.1)
  return jaro + prefixLength * 0.1 * (1 - jaro)
}

// ============================================
// íšŒì‚¬ëª… ì •ê·œí™” í•¨ìˆ˜
// ============================================

function normalizeCompanyName(name: string): string {
  if (!name) return ''

  return name
    .replace(/\(ì£¼\)/g, '')           // (ì£¼) ì œê±°
    .replace(/\(ìœ \)/g, '')           // (ìœ ) ì œê±°
    .replace(/ãˆœ/g, '')                // ãˆœ ì œê±°
    .replace(/ì£¼ì‹íšŒì‚¬/g, '')         // ì£¼ì‹íšŒì‚¬ ì œê±°
    .replace(/ìœ í•œíšŒì‚¬/g, '')         // ìœ í•œíšŒì‚¬ ì œê±°
    .replace(/ìœ í•œì±…ì„íšŒì‚¬/g, '')     // ìœ í•œì±…ì„íšŒì‚¬ ì œê±°
    .replace(/\s+/g, '')              // ëª¨ë“  ê³µë°± ì œê±°
    .toLowerCase()                    // ì†Œë¬¸ìë¡œ ë³€í™˜
    .trim()
}


// ============================================
// ì ìˆ˜ ê³„ì‚° ë¡œì§ (ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜)
// ============================================

interface UserPreferences {
  preferred_job_types?: string[]
  preferred_locations?: string[]
  career_level?: string
  preferred_company_sizes?: string[]
  preferred_industries?: string[]
  min_salary?: number
  work_style?: string[]  // ê³ ìš©í˜•íƒœ í•„í„°: ì •ê·œì§, ê³„ì•½ì§, ì¸í„´ ë“±
  preferred_company_types?: string[]  // ê¸°ì—… ìœ í˜• í•„í„°: ëŒ€ê¸°ì—…, ìŠ¤íƒ€íŠ¸ì—… ë“±
  preferred_education?: string[]  // í•™ë ¥ í•„í„°: ë¬´ê´€, ê³ ì¡¸, ì „ë¬¸ëŒ€ì¡¸, í•™ì‚¬, ì„ì‚¬, ë°•ì‚¬
}

interface KeywordWeight {
  keyword: string
  weight: number
}

interface CompanyPref {
  company_name: string
  preference_score: number
}

// í–‰ë™ ê¸°ë°˜ í•™ìŠµ ê°€ì¤‘ì¹˜
interface LearnedWeight {
  feature_type: string  // 'depth_two', 'keyword', 'region'
  feature_value: string
  weight: number        // -1.0 ~ 1.0
  confidence: number    // 0 ~ 1.0 (ë…¸ì¶œ íšŸìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„)
}

interface JobRow {
  id: string
  source: string
  company: string
  company_image: string | null
  company_type: string | null  // ê¸°ì—… ìœ í˜• ì¶”ê°€
  title: string
  regions: string[] | null
  location: string | null
  career_min: number | null
  career_max: number | null
  employee_types: string[] | null
  deadline_type: string | null
  end_date: string | null
  depth_ones: string[] | null
  depth_twos: string[] | null
  keywords: string[] | null
  views: number | null
  detail: Record<string, string> | null
  education: string | null  // í•™ë ¥ ì¶”ê°€
  original_created_at: string | null
  last_modified_at: string | null
  crawled_at: string
  is_active: boolean
}

function scoreJob(
  job: JobRow,
  prefs: UserPreferences | null,
  keywordWeights: KeywordWeight[],
  companyPrefs: CompanyPref[],
  learnedWeights: LearnedWeight[] = [],  // í–‰ë™ ê¸°ë°˜ í•™ìŠµ ê°€ì¤‘ì¹˜
  companyType: string | null = null,
  isInDB: boolean = false
): { score: number; reasons: string[]; warnings: string[]; matchesFilter: boolean } {
  let score = 50
  const reasons: string[] = []
  const warnings: string[] = []
  let matchesFilter = true

  const jobText = `${job.company} ${job.title} ${job.depth_ones?.join(' ') || ''} ${job.depth_twos?.join(' ') || ''} ${job.keywords?.join(' ') || ''} ${job.detail?.raw_content || ''} ${job.detail?.main_tasks || ''} ${job.detail?.requirements || ''}`.toLowerCase()

  if (!prefs) {
    return { score: 50, reasons: ['ê¸°ë³¸ ì¶”ì²œ'], warnings: [], matchesFilter: true }
  }

  // 1. ì§ë¬´ ë§¤ì¹­ (preferred_job_types) - í•„ìˆ˜ í•„í„°
  // ë‹¤ì¸µ ë§¤ì¹­: depth_twos (ìš°ì„ ) > jobText (ë³´ì¡°) > depth_ones (ì°¸ê³ )
  if (prefs.preferred_job_types?.length) {
    const jobDepthTwos = job.depth_twos || []
    const jobDepthOnes = job.depth_ones || []
    let jobMatched = false
    let bestMatchScore = 0
    let bestMatchName = ''
    let matchType = ''

    for (const prefType of prefs.preferred_job_types) {
      const prefLower = prefType.toLowerCase()

      // 1ë‹¨ê³„: depth_twosì—ì„œ ì •í™• ë§¤ì¹­ (ìµœìš°ì„  - 15ì )
      const exactMatchInDepthTwos = jobDepthTwos.some(t => {
        const jobTypeLower = t.toLowerCase()
        return jobTypeLower === prefLower ||
          jobTypeLower.includes(prefLower) ||
          prefLower.includes(jobTypeLower)
      })

      if (exactMatchInDepthTwos) {
        score += 15
        reasons.push(`${prefType}`)
        jobMatched = true
        break
      }

      // 2ë‹¨ê³„: jobTextì—ì„œ ë§¤ì¹­ (ë³¸ë¬¸ í‚¤ì›Œë“œ - 10ì )
      if (jobText.includes(prefLower)) {
        score += 10
        reasons.push(`${prefType} (ë³¸ë¬¸)`)
        jobMatched = true
        break
      }

      // 3ë‹¨ê³„: depth_twosì—ì„œ Jaro-Winkler ìœ ì‚¬ë„ ë§¤ì¹­ (ì„ê³„ê°’ 0.85 - 12ì )
      for (const jobDepthTwo of jobDepthTwos) {
        const similarity = jaroWinklerDistance(prefLower, jobDepthTwo.toLowerCase())
        if (similarity >= 0.85 && similarity > bestMatchScore) {
          bestMatchScore = similarity
          bestMatchName = prefType
          matchType = 'similarity'
        }
      }

      // 4ë‹¨ê³„: depth_onesì—ì„œ ë§¤ì¹­ (ëŒ€ë¶„ë¥˜ ì¼ì¹˜ - ì•½í•œ ì‹ í˜¸, 5ì )
      // ì˜ˆ: ì‚¬ìš©ìê°€ "í”„ë¡ íŠ¸ì—”ë“œ" ì„ íƒ, ê³µê³ ì— "ê°œë°œ" ëŒ€ë¶„ë¥˜ë§Œ ìˆëŠ” ê²½ìš°
      const matchInDepthOnes = jobDepthOnes.some(d => {
        const dLower = d.toLowerCase()
        // "ê°œë°œ" ëŒ€ë¶„ë¥˜ ì•ˆì— í”„ë¡ íŠ¸ì—”ë“œê°€ ì†í•˜ëŠ”ì§€ ì˜ë¯¸ì  ì—°ê´€ì„± ì²´í¬
        return prefLower.includes(dLower) || dLower.includes(prefLower)
      })

      if (!jobMatched && matchInDepthOnes && bestMatchScore < 0.85) {
        bestMatchScore = 0.7 // ì„ê³„ê°’ë³´ë‹¤ ë‚®ì§€ë§Œ ì°¸ê³ ìš©
        bestMatchName = prefType
        matchType = 'depth_one'
      }
    }

    // ìœ ì‚¬ë„ ë§¤ì¹­ ì„±ê³µ
    if (!jobMatched && bestMatchScore >= 0.85) {
      score += 12
      reasons.push(`${bestMatchName} (ìœ ì‚¬)`)
      jobMatched = true
    }

    // ì•½í•œ ë§¤ì¹­ (ëŒ€ë¶„ë¥˜ë§Œ ì¼ì¹˜)
    if (!jobMatched && matchType === 'depth_one') {
      score += 5
      reasons.push(`${bestMatchName} (ê´€ë ¨)`)
      jobMatched = true
    }

    // ì§ë¬´ê°€ í•˜ë‚˜ë„ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ í•„í„° ë¶ˆí†µê³¼
    if (!jobMatched) {
      matchesFilter = false
      score = 0
      warnings.push('âš ï¸ ì„ í˜¸ ì§ë¬´ ë¶ˆì¼ì¹˜')
    }
  }

  // 2. ì§€ì—­ í•„í„° (ì—„ê²©í•œ í•„í„°ë§)
  if (prefs.preferred_locations?.length && job.location) {
    const locationMatch = prefs.preferred_locations.some(loc =>
      job.location!.includes(loc) || loc.includes(job.location!)
    )
    if (!locationMatch) {
      matchesFilter = false
      warnings.push(`âš ï¸ ${job.location} (ì„ í˜¸ ì§€ì—­ ë¶ˆì¼ì¹˜)`)
    }
  }

  // 3. ê²½ë ¥ í•„í„° (ì—„ê²©í•œ í•„í„°ë§)
  if (prefs.career_level) {
    const careerLevels = prefs.career_level.split(',').filter(Boolean)
    let careerMatched = false

    for (const level of careerLevels) {
      if (level === 'ì‹ ì…' || level === 'ê²½ë ¥ë¬´ê´€') {
        // ì‹ ì…/ê²½ë ¥ë¬´ê´€: career_minì´ 0ì´ê±°ë‚˜ nullì¸ ê³µê³ 
        if (job.career_min === 0 || job.career_min === null) {
          careerMatched = true
          reasons.push('ì‹ ì… ê°€ëŠ¥')
          break
        }
      } else if (level === '1-3') {
        // 1-3ë…„: career_minì´ 3 ì´í•˜ì¸ ê³µê³ 
        if (job.career_min === null || job.career_min <= 3) {
          careerMatched = true
          break
        }
      } else if (level === '3-5') {
        // 3-5ë…„: career_minì´ 5 ì´í•˜ì¸ ê³µê³ 
        if (job.career_min !== null && job.career_min >= 1 && job.career_min <= 5) {
          careerMatched = true
          break
        }
      } else if (level === '5-10') {
        // 5-10ë…„: career_minì´ 5-10 ë²”ìœ„ì¸ ê³µê³ 
        if (job.career_min !== null && job.career_min >= 3 && job.career_min <= 10) {
          careerMatched = true
          break
        }
      } else if (level === '10+') {
        // 10ë…„+: career_minì´ 10 ì´ìƒì¸ ê³µê³ 
        if (job.career_min !== null && job.career_min >= 10) {
          careerMatched = true
          break
        }
      }
    }

    if (!careerMatched) {
      matchesFilter = false
      const minCareer = job.career_min !== null ? `ê²½ë ¥ ${job.career_min}ë…„ ì´ìƒ` : 'ê²½ë ¥ ìš”êµ¬ì‚¬í•­ ë¶ˆëª…í™•'
      warnings.push(`âš ï¸ ${minCareer} (ê²½ë ¥ ì¡°ê±´ ë¶ˆì¼ì¹˜)`)
    }
  }

  // 3.5 ê³ ìš©í˜•íƒœ í•„í„° (ì—„ê²©í•œ í•„í„°ë§)
  if (prefs.work_style?.length) {
    if (!job.employee_types || job.employee_types.length === 0) {
      // employee_types ì •ë³´ê°€ ì—†ëŠ” ê³µê³ ëŠ” í•„í„°ë§ ì œì™¸
      matchesFilter = false
      warnings.push(`âš ï¸ ê³ ìš©í˜•íƒœ ì •ë³´ ì—†ìŒ`)
    } else {
      // ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­: 'ì¸í„´'ì´ 'ì „í™˜í˜•ì¸í„´', 'ì²´í—˜í˜•ì¸í„´' ë“±ë„ ë§¤ì¹­
      const match = prefs.work_style.some(pref =>
        job.employee_types!.some(jobType =>
          jobType.includes(pref) || pref.includes(jobType)
        )
      )

      if (!match) {
        matchesFilter = false
        warnings.push(`âš ï¸ ê³ ìš©í˜•íƒœ ë¶ˆì¼ì¹˜`)
      } else {
        reasons.push('í¬ë§ ê³ ìš©í˜•íƒœ')
      }
    }
  }

  // 3.6 ê¸°ì—… ìœ í˜• í•„í„° (ì—„ê²©í•œ í•„í„°ë§)
  if (prefs.preferred_company_types?.length) {
    if (!companyType || companyType === 'ê¸°íƒ€') {
      // company_type ì •ë³´ê°€ ì—†ê±°ë‚˜ 'ê¸°íƒ€'ì¸ ê³µê³ ëŠ” í•„í„°ë§ ì œì™¸
      matchesFilter = false
      warnings.push(`âš ï¸ ê¸°ì—… ìœ í˜• ì •ë³´ ì—†ìŒ`)
    } else {
      const match = prefs.preferred_company_types.includes(companyType)
      if (!match) {
        matchesFilter = false
        warnings.push(`âš ï¸ ${companyType} (ì„ í˜¸ ìœ í˜• ë¶ˆì¼ì¹˜)`)
      } else {
        reasons.push(`${companyType}`)
      }
    }
  }

  // 3.7 í•™ë ¥ í•„í„° (ì—„ê²©í•œ í•„í„°ë§ - ì •í™•íˆ ì¼ì¹˜ë§Œ)
  if (prefs.preferred_education?.length) {
    if (!job.education) {
      // education ì •ë³´ê°€ ì—†ëŠ” ê³µê³ ëŠ” í•„í„°ë§ ì œì™¸
      matchesFilter = false
      warnings.push(`âš ï¸ í•™ë ¥ ì •ë³´ ì—†ìŒ`)
    } else {
      const match = prefs.preferred_education.includes(job.education)
      
      if (!match) {
        matchesFilter = false
        warnings.push(`âš ï¸ ${job.education} ìš”êµ¬ (í•™ë ¥ ë¶ˆì¼ì¹˜)`)
      } else {
        reasons.push(`í•™ë ¥ ${job.education}`)
      }
    }
  }

  // 3.8 DBì— ìˆëŠ” íšŒì‚¬ ìš°ì„ ìˆœìœ„ (í¬ë¡¤ë§ëœ ì •ë³´ê°€ ìˆëŠ” íšŒì‚¬)
  if (isInDB) {
    score += 5
    // reasonsì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ (UIì— í‘œì‹œ ì•ˆ í•¨, ë‚´ë¶€ ìš°ì„ ìˆœìœ„ë§Œ)
  }

  // 4. í•™ìŠµëœ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
  for (const kw of keywordWeights) {
    if (jobText.includes(kw.keyword.toLowerCase())) {
      const impact = Math.max(-5, Math.min(5, kw.weight))
      score += impact
      if (Math.abs(kw.weight) >= 3) {
        if (kw.weight > 0) reasons.push(`ğŸ“ˆ "${kw.keyword}"`)
        else warnings.push(`ğŸ“‰ "${kw.keyword}"`)
      }
    }
  }

  // 5. í•™ìŠµëœ íšŒì‚¬ ì„ í˜¸ë„
  const companyPref = companyPrefs.find(c =>
    job.company.includes(c.company_name) || c.company_name.includes(job.company)
  )
  if (companyPref && Math.abs(companyPref.preference_score) >= 2) {
    const impact = Math.max(-10, Math.min(10, companyPref.preference_score))
    score += impact
    if (companyPref.preference_score >= 2) reasons.push('ğŸ¢ ì„ í˜¸ ê¸°ì—…')
    else if (companyPref.preference_score <= -2) warnings.push('ğŸ¢ ë¹„ì„ í˜¸ ê¸°ì—…')
  }

  // 6. í–‰ë™ ê¸°ë°˜ í•™ìŠµ ê°€ì¤‘ì¹˜ ì ìš©
  if (learnedWeights.length > 0) {
    let learnedBonus = 0
    const learnedReasons: string[] = []

    const jobDepthTwos = (job.depth_twos || []).map(d => d.toLowerCase())
    const jobKeywords = (job.keywords || []).map(k => k.toLowerCase())
    const jobRegions = (job.regions || []).map(r => r.toLowerCase())

    for (const lw of learnedWeights) {
      const featureLower = lw.feature_value.toLowerCase()
      let matched = false

      if (lw.feature_type === 'depth_two') {
        matched = jobDepthTwos.some(d => d.includes(featureLower) || featureLower.includes(d))
      } else if (lw.feature_type === 'keyword') {
        matched = jobKeywords.some(k => k.includes(featureLower) || featureLower.includes(k))
      } else if (lw.feature_type === 'region') {
        matched = jobRegions.some(r => r.includes(featureLower) || featureLower.includes(r))
      }

      if (matched) {
        // ê°€ì¤‘ì¹˜ * ì‹ ë¢°ë„ * ìµœëŒ€ 10ì 
        const impact = Math.round(lw.weight * lw.confidence * 10)
        learnedBonus += impact

        // ì˜í–¥ë ¥ ìˆëŠ” í•™ìŠµ ê²°ê³¼ë§Œ í‘œì‹œ
        if (Math.abs(impact) >= 3) {
          if (impact > 0) {
            learnedReasons.push(`ğŸ§  ${lw.feature_value}`)
          }
        }
      }
    }

    // í•™ìŠµ ë³´ë„ˆìŠ¤ ì ìš© (ìµœëŒ€ Â±15ì )
    const cappedBonus = Math.max(-15, Math.min(15, learnedBonus))
    score += cappedBonus

    // ìƒìœ„ 2ê°œ í•™ìŠµ ì´ìœ ë§Œ ì¶”ê°€
    reasons.push(...learnedReasons.slice(0, 2))
  }

  // 7. ìµœì‹  ê³µê³  ë¶€ìŠ¤íŠ¸
  if (job.crawled_at) {
    const hoursSince = (Date.now() - new Date(job.crawled_at).getTime()) / (1000 * 60 * 60)
    if (hoursSince <= 24) {
      score += 5
      reasons.push('ğŸ†• ì‹ ê·œ')
    } else if (hoursSince <= 72) {
      score += 3
    }
  }

  score = Math.max(0, Math.min(100, score))

  // ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±° (ìˆœì„œ ìœ ì§€)
  const uniqueReasons = Array.from(new Set(reasons))

  return { score, reasons: uniqueReasons, warnings, matchesFilter }
}

// ============================================
// API Handler
// ============================================

export async function GET(request: Request) {
  const startTime = Date.now()
  try {
    const { searchParams } = new URL(request.url)
    const limit = parseInt(searchParams.get('limit') || '20')
    const offset = parseInt(searchParams.get('offset') || '0')

    // ì¸ì¦ í—¤ë”ì—ì„œ í† í° ì¶”ì¶œ
    const authHeader = request.headers.get('authorization')
    const token = authHeader?.replace('Bearer ', '')

    console.log('[API /jobs] Start - Token exists:', !!token)

    // í† í°ì´ ì—†ìœ¼ë©´ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: ê¸°ë³¸ ê³µê³  ì œê³µ
    if (!token) {
      console.log('[API /jobs] No token - using guest mode')
      const supabase = createClient(supabaseUrl, supabaseAnonKey)

      const { data: jobs, error: jobsError } = await supabase
        .from('jobs')
        .select('*')
        .eq('is_active', true)
        .order('crawled_at', { ascending: false })
        .range(offset, offset + limit - 1)

      if (jobsError) {
        console.error('Jobs query error:', jobsError)
        return NextResponse.json({ error: 'Failed to fetch jobs' }, { status: 500 })
      }

      if (!jobs || jobs.length === 0) {
        console.log('[API /jobs] Guest mode - No jobs found')
        return NextResponse.json({
          jobs: [],
          total: 0,
          limit,
          offset,
          message: 'No jobs available. Please run the crawler first.',
        })
      }

      console.log('[API /jobs] Guest mode - Returning', jobs.length, 'jobs')

      // ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: ìµœì‹ ìˆœ ê³µê³ , ê¸°ë³¸ ì ìˆ˜ 50ì 
      const now = Date.now()
      const basicJobs = jobs.map((job: JobRow) => {
        const isNew = (now - new Date(job.crawled_at).getTime()) < 24 * 60 * 60 * 1000

        return {
          id: job.id,
          company: job.company,
          company_image: job.company_image,
          company_type: job.company_type,
          title: job.title,
          location: job.location || 'ìœ„ì¹˜ ë¯¸ì •',
          score: 50,
          reason: isNew ? 'ğŸ†• ì‹ ê·œ ê³µê³ ' : 'ìµœì‹  ê³µê³ ',
          reasons: isNew ? ['ğŸ†• ì‹ ê·œ'] : ['ìµœì‹  ê³µê³ '],
          warnings: [],
          link: `https://zighang.com/recruitment/${job.id}`,
          source: job.source,
          crawledAt: job.crawled_at,
          detail: job.detail,
          depth_ones: job.depth_ones,
          depth_twos: job.depth_twos,
          keywords: job.keywords,
          career_min: job.career_min,
          career_max: job.career_max,
          employee_types: job.employee_types,
          deadline_type: job.deadline_type,
          end_date: job.end_date,
          is_new: isNew,
        }
      })

      return NextResponse.json({
        jobs: basicJobs,
        total: basicJobs.length,
        limit,
        offset,
        hasMore: jobs.length === limit, // ì •í™•í•œ hasMoreëŠ” ì•Œ ìˆ˜ ì—†ì§€ë§Œ ì¶”ì •
      })
    }

    // === ë¡œê·¸ì¸ ì‚¬ìš©ì: ë§ì¶¤í˜• ì¶”ì²œ ===
    console.log('[API /jobs] Authenticated user mode')

    // í† í°ì„ í¬í•¨í•œ supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (RLS í†µê³¼ìš©)
    const supabase = createClient(supabaseUrl, supabaseAnonKey, {
      global: {
        headers: { Authorization: `Bearer ${token}` },
      },
    })

    // í† í°ìœ¼ë¡œ ì§ì ‘ ìœ ì € í™•ì¸
    const { data: { user }, error: userError } = await supabase.auth.getUser(token)
    console.log(`[API /jobs] +${Date.now() - startTime}ms - Auth check done`)

    if (!user || userError) {
      console.log('[API /jobs] Auth failed:', userError?.message)
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    console.log('[API /jobs] User authenticated:', user.id)

    // ë³‘ë ¬ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const [prefsResult, keywordsResult, companiesResult, seenResult, learnedResult] = await Promise.all([
      // 1. ì‚¬ìš©ì ì„ í˜¸ë„
      supabase
        .from('user_preferences')
        .select('*')
        .eq('user_id', user.id)
        .maybeSingle(),
      // 2. í•™ìŠµëœ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ (ìˆ˜ë™ ì„¤ì •)
      supabase
        .from('keyword_weights')
        .select('keyword, weight')
        .eq('user_id', user.id)
        .order('weight', { ascending: false })
        .limit(100),
      // 3. í•™ìŠµëœ íšŒì‚¬ ì„ í˜¸ë„
      supabase
        .from('company_preference')
        .select('company_name, preference_score')
        .eq('user_id', user.id),
      // 4. ì´ë¯¸ ë³¸ ê³µê³  ID
      supabase
        .from('user_job_actions')
        .select('job_id')
        .eq('user_id', user.id),
      // 5. í–‰ë™ ê¸°ë°˜ í•™ìŠµ ê°€ì¤‘ì¹˜
      supabase.rpc('get_user_learned_weights', { p_user_id: user.id }),
    ])

    console.log(`[API /jobs] +${Date.now() - startTime}ms - Parallel queries done`)

    const preferences: UserPreferences | null = prefsResult.data
    const keywordWeights: KeywordWeight[] = keywordsResult.data || []
    const companyPrefs: CompanyPref[] = companiesResult.data || []
    const seenJobIds = new Set(seenResult.data?.map(a => a.job_id) || [])
    const learnedWeights: LearnedWeight[] = learnedResult.data || []

    console.log(`[API /jobs] Learned weights: ${learnedWeights.length} features`)

    // 5. í™œì„± ê³µê³  ê°€ì ¸ì˜¤ê¸° (RPC í•¨ìˆ˜ë¡œ ì§ë¬´/ì§€ì—­ í•„í„°ë§)
    const fetchLimit = Math.max(2000, (offset + limit) * 5)

    const rpcStartTime = Date.now()

    // RPC íŒŒë¼ë¯¸í„°
    const rpcParams = {
      p_job_types: preferences?.preferred_job_types?.length
        ? preferences.preferred_job_types
        : null,
      p_locations: preferences?.preferred_locations?.length
        ? preferences.preferred_locations
        : null,
      p_limit: fetchLimit
    }

    console.log('[API /jobs] RPC params:', JSON.stringify(rpcParams))

    let { data: jobs, error: jobsError } = await supabase.rpc('get_filtered_jobs', rpcParams) as { data: JobRow[] | null, error: any }

    console.log(`[API /jobs] +${Date.now() - startTime}ms - RPC done (took ${Date.now() - rpcStartTime}ms), returned: ${jobs ? jobs.length : 0} jobs`)

    // jsonb íƒ€ì…ì„ ë°°ì—´ë¡œ ë³€í™˜
    if (jobs && jobs.length > 0) {
      jobs = jobs.map((job: any) => ({
        ...job,
        depth_ones: Array.isArray(job.depth_ones) ? job.depth_ones : (job.depth_ones || []),
        depth_twos: Array.isArray(job.depth_twos) ? job.depth_twos : (job.depth_twos || []),
        keywords: Array.isArray(job.keywords) ? job.keywords : (job.keywords || []),
        regions: Array.isArray(job.regions) ? job.regions : (job.regions || []),
        employee_types: Array.isArray(job.employee_types) ? job.employee_types : (job.employee_types || []),
      }))
    }

    if (jobsError) {
      console.error('[API /jobs] RPC error:', jobsError)
      console.error('[API /jobs] RPC may have timed out. Indexes may need time to build.')
      return NextResponse.json({ error: 'Failed to fetch jobs' }, { status: 500 })
    }


    if (!jobs || jobs.length === 0) {
      return NextResponse.json({
        jobs: [],
        total: 0,
        limit,
        offset,
        message: 'No jobs available. Please run the crawler first.',
      })
    }

    // company_typeì€ ì´ë¯¸ jobs í…Œì´ë¸”ì— í¬í•¨ë˜ì–´ ìˆìŒ (ë³„ë„ ì¡°íšŒ ë¶ˆí•„ìš”)

    // 6. ì´ë¯¸ ë³¸ ê³µê³  ì œì™¸ + ì ìˆ˜ ê³„ì‚° + í•„í„°ë§ + ì •ë ¬
    const now = Date.now()
    const scoredJobs = jobs
      .filter((job: JobRow) => !seenJobIds.has(job.id))
      .map((job: JobRow) => {
        const companyType = job.company_type || 'ê¸°íƒ€'
        const isInDB = job.company_type !== null && job.company_type !== 'ê¸°íƒ€'
        const { score, reasons, warnings, matchesFilter } = scoreJob(job, preferences, keywordWeights, companyPrefs, learnedWeights, companyType, isInDB)
        const isNew = (now - new Date(job.crawled_at).getTime()) < 24 * 60 * 60 * 1000

        return {
          id: job.id,
          company: job.company,
          company_image: job.company_image,
          company_type: job.company_type,
          title: job.title,
          location: job.location || 'ìœ„ì¹˜ ë¯¸ì •',
          score,
          reason: reasons[0] || 'ì¶”ì²œ ê³µê³ ',
          reasons,
          warnings,
          link: `https://zighang.com/recruitment/${job.id}`,
          source: job.source,
          crawledAt: job.crawled_at,
          detail: job.detail,
          depth_ones: job.depth_ones,
          depth_twos: job.depth_twos,
          keywords: job.keywords,
          career_min: job.career_min,
          career_max: job.career_max,
          employee_types: job.employee_types,
          deadline_type: job.deadline_type,
          end_date: job.end_date,
          is_new: isNew,
          matchesFilter,
        }
      })
      .filter(j => j.matchesFilter) // í•„í„° í†µê³¼í•œ ê³µê³ ë§Œ
      .sort((a, b) => {
        if (b.score !== a.score) return b.score - a.score
        return new Date(b.crawledAt).getTime() - new Date(a.crawledAt).getTime()
      })

    // 7. 40ì  ì´ìƒ í•„í„° + í˜ì´ì§€ë„¤ì´ì…˜
    const passedJobs = scoredJobs.filter(j => j.score >= 40)
    const paginatedJobs = passedJobs.slice(offset, offset + limit)

    console.log(`[API /jobs] +${Date.now() - startTime}ms - Total done, returning ${paginatedJobs.length} jobs`)

    return NextResponse.json({
      jobs: paginatedJobs,
      total: passedJobs.length,
      limit,
      offset,
      hasMore: offset + limit < passedJobs.length,
    })

  } catch (error) {
    console.error('Error fetching jobs:', error)
    return NextResponse.json(
      { error: 'Failed to fetch jobs' },
      { status: 500 }
    )
  }
}
