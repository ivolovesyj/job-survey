import { NextResponse } from 'next/server'
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

// ============================================
// ì ìˆ˜ ê³„ì‚° ë¡œì§ (ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜)
// ============================================

interface UserPreferences {
  preferred_job_types?: string[]
  preferred_locations?: string[]
  career_level?: string
  preferred_company_sizes?: string[]
  preferred_industries?: string[]
  min_salary?: number
  work_style?: string[]  // ê³ ìš©í˜•íƒœ í•„í„°: ì •ê·œì§, ê³„ì•½ì§, ì¸í„´ ë“±
}

interface KeywordWeight {
  keyword: string
  weight: number
}

interface CompanyPref {
  company_name: string
  preference_score: number
}

interface JobRow {
  id: string
  source: string
  company: string
  company_image: string | null
  title: string
  regions: string[] | null
  location: string | null
  career_min: number | null
  career_max: number | null
  employee_types: string[] | null
  deadline_type: string | null
  end_date: string | null
  depth_ones: string[] | null
  depth_twos: string[] | null
  keywords: string[] | null
  views: number | null
  detail: Record<string, string> | null
  original_created_at: string | null
  last_modified_at: string | null
  crawled_at: string
  is_active: boolean
}

function scoreJob(
  job: JobRow,
  prefs: UserPreferences | null,
  keywordWeights: KeywordWeight[],
  companyPrefs: CompanyPref[]
): { score: number; reasons: string[]; warnings: string[]; matchesFilter: boolean } {
  let score = 50
  const reasons: string[] = []
  const warnings: string[] = []
  let matchesFilter = true

  const jobText = `${job.company} ${job.title} ${job.depth_ones?.join(' ') || ''} ${job.depth_twos?.join(' ') || ''} ${job.keywords?.join(' ') || ''} ${job.detail?.raw_content || ''} ${job.detail?.main_tasks || ''} ${job.detail?.requirements || ''}`.toLowerCase()

  if (!prefs) {
    return { score: 50, reasons: ['ê¸°ë³¸ ì¶”ì²œ'], warnings: [], matchesFilter: true }
  }

  // 1. ì§ë¬´ ë§¤ì¹­ (preferred_job_types vs depth_ones/depth_twos) - í•„ìˆ˜ í•„í„°
  if (prefs.preferred_job_types?.length) {
    const jobTypes = [...(job.depth_ones || []), ...(job.depth_twos || [])]
    let jobMatched = false

    for (const prefType of prefs.preferred_job_types) {
      const prefLower = prefType.toLowerCase()

      // ë” ìœ ì—°í•œ ë§¤ì¹­: ì •í™•í•œ ë§¤ì¹­ ë˜ëŠ” ë¶€ë¶„ ë§¤ì¹­
      const matches = jobTypes.some(t => {
        const jobTypeLower = t.toLowerCase()
        // 1) ì •í™•íˆ ì¼ì¹˜
        if (jobTypeLower === prefLower) return true
        // 2) ì„ í˜¸ ì§ë¬´ê°€ ê³µê³  ì§ë¬´ì— í¬í•¨ë¨
        if (jobTypeLower.includes(prefLower)) return true
        // 3) ê³µê³  ì§ë¬´ê°€ ì„ í˜¸ ì§ë¬´ì— í¬í•¨ë¨
        if (prefLower.includes(jobTypeLower)) return true
        return false
      }) || jobText.includes(prefLower)

      if (matches) {
        score += 15
        reasons.push(`âœ“ ${prefType}`)
        jobMatched = true
        break
      }
    }

    // ì§ë¬´ê°€ í•˜ë‚˜ë„ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ í•„í„° ë¶ˆí†µê³¼
    if (!jobMatched) {
      matchesFilter = false
      score = 0
      warnings.push('âš ï¸ ì„ í˜¸ ì§ë¬´ ë¶ˆì¼ì¹˜')
    }
  }

  // 2. ì§€ì—­ ë§¤ì¹­
  if (prefs.preferred_locations?.length && job.location) {
    const locationMatch = prefs.preferred_locations.some(loc =>
      job.location!.includes(loc) || loc.includes(job.location!)
    )
    if (locationMatch) {
      score += 10
      reasons.push('âœ“ ì„ í˜¸ ì§€ì—­')
    } else {
      score -= 30
      warnings.push(`âš ï¸ ${job.location} (ì„ í˜¸ ì§€ì—­ ì•„ë‹˜)`)
    }
  }

  // 3. ê²½ë ¥ ë§¤ì¹­
  if (prefs.career_level) {
    const isNewbie = prefs.career_level === 'ì‹ ì…' || prefs.career_level === 'ê²½ë ¥ë¬´ê´€'
    if (isNewbie) {
      if (job.career_min === 0 || job.career_min === null) {
        score += 5
        reasons.push('âœ“ ì‹ ì… ê°€ëŠ¥')
      } else if (job.career_min && job.career_min >= 3) {
        score -= 20
        warnings.push(`âš ï¸ ê²½ë ¥ ${job.career_min}ë…„ ì´ìƒ`)
      }
    }
  }

  // 3.5 ê³ ìš©í˜•íƒœ ë§¤ì¹­
  if (prefs.work_style?.length && job.employee_types?.length) {
    const match = prefs.work_style.some(ws => job.employee_types!.includes(ws))
    if (match) {
      score += 5
      reasons.push('âœ“ í¬ë§ ê³ ìš©í˜•íƒœ')
    }
  }

  // 4. í•™ìŠµëœ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
  for (const kw of keywordWeights) {
    if (jobText.includes(kw.keyword.toLowerCase())) {
      const impact = Math.max(-5, Math.min(5, kw.weight))
      score += impact
      if (Math.abs(kw.weight) >= 3) {
        if (kw.weight > 0) reasons.push(`ğŸ“ˆ "${kw.keyword}"`)
        else warnings.push(`ğŸ“‰ "${kw.keyword}"`)
      }
    }
  }

  // 5. í•™ìŠµëœ íšŒì‚¬ ì„ í˜¸ë„
  const companyPref = companyPrefs.find(c =>
    job.company.includes(c.company_name) || c.company_name.includes(job.company)
  )
  if (companyPref && Math.abs(companyPref.preference_score) >= 2) {
    const impact = Math.max(-10, Math.min(10, companyPref.preference_score))
    score += impact
    if (companyPref.preference_score >= 2) reasons.push('ğŸ¢ ì„ í˜¸ ê¸°ì—…')
    else if (companyPref.preference_score <= -2) warnings.push('ğŸ¢ ë¹„ì„ í˜¸ ê¸°ì—…')
  }

  // 6. ìµœì‹  ê³µê³  ë¶€ìŠ¤íŠ¸
  if (job.crawled_at) {
    const hoursSince = (Date.now() - new Date(job.crawled_at).getTime()) / (1000 * 60 * 60)
    if (hoursSince <= 24) {
      score += 5
      reasons.push('ğŸ†• ì‹ ê·œ')
    } else if (hoursSince <= 72) {
      score += 3
    }
  }

  score = Math.max(0, Math.min(100, score))
  return { score, reasons, warnings, matchesFilter }
}

// ============================================
// API Handler
// ============================================

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    const limit = parseInt(searchParams.get('limit') || '20')
    const offset = parseInt(searchParams.get('offset') || '0')

    // ì¸ì¦ í—¤ë”ì—ì„œ í† í° ì¶”ì¶œ
    const authHeader = request.headers.get('authorization')
    const token = authHeader?.replace('Bearer ', '')

    // í† í°ì´ ì—†ìœ¼ë©´ ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: ê¸°ë³¸ ê³µê³  ì œê³µ
    if (!token) {
      const supabase = createClient(supabaseUrl, supabaseAnonKey)

      const { data: jobs, error: jobsError } = await supabase
        .from('jobs')
        .select('*')
        .eq('is_active', true)
        .order('crawled_at', { ascending: false })
        .range(offset, offset + limit - 1)

      if (jobsError) {
        console.error('Jobs query error:', jobsError)
        return NextResponse.json({ error: 'Failed to fetch jobs' }, { status: 500 })
      }

      if (!jobs || jobs.length === 0) {
        return NextResponse.json({
          jobs: [],
          total: 0,
          limit,
          offset,
          message: 'No jobs available. Please run the crawler first.',
        })
      }

      // ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: ìµœì‹ ìˆœ ê³µê³ , ê¸°ë³¸ ì ìˆ˜ 50ì 
      const now = Date.now()
      const basicJobs = jobs.map((job: JobRow) => {
        const isNew = (now - new Date(job.crawled_at).getTime()) < 24 * 60 * 60 * 1000

        return {
          id: job.id,
          company: job.company,
          company_image: job.company_image,
          title: job.title,
          location: job.location || 'ìœ„ì¹˜ ë¯¸ì •',
          score: 50,
          reason: isNew ? 'ğŸ†• ì‹ ê·œ ê³µê³ ' : 'ìµœì‹  ê³µê³ ',
          reasons: isNew ? ['ğŸ†• ì‹ ê·œ'] : ['ìµœì‹  ê³µê³ '],
          warnings: [],
          link: `https://zighang.com/recruitment/${job.id}`,
          source: job.source,
          crawledAt: job.crawled_at,
          detail: job.detail,
          depth_ones: job.depth_ones,
          depth_twos: job.depth_twos,
          keywords: job.keywords,
          career_min: job.career_min,
          career_max: job.career_max,
          employee_types: job.employee_types,
          deadline_type: job.deadline_type,
          end_date: job.end_date,
          is_new: isNew,
        }
      })

      return NextResponse.json({
        jobs: basicJobs,
        total: basicJobs.length,
        limit,
        offset,
        hasMore: jobs.length === limit, // ì •í™•í•œ hasMoreëŠ” ì•Œ ìˆ˜ ì—†ì§€ë§Œ ì¶”ì •
      })
    }

    // === ë¡œê·¸ì¸ ì‚¬ìš©ì: ë§ì¶¤í˜• ì¶”ì²œ ===

    // í† í°ì„ í¬í•¨í•œ supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (RLS í†µê³¼ìš©)
    const supabase = createClient(supabaseUrl, supabaseAnonKey, {
      global: {
        headers: { Authorization: `Bearer ${token}` },
      },
    })

    // í† í°ìœ¼ë¡œ ì§ì ‘ ìœ ì € í™•ì¸
    const { data: { user }, error: userError } = await supabase.auth.getUser(token)

    if (!user || userError) {
      console.log('[Jobs API] Auth failed:', userError?.message)
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    // ë³‘ë ¬ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const [prefsResult, keywordsResult, companiesResult, seenResult] = await Promise.all([
      // 1. ì‚¬ìš©ì ì„ í˜¸ë„
      supabase
        .from('user_preferences')
        .select('*')
        .eq('user_id', user.id)
        .single(),
      // 2. í•™ìŠµëœ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
      supabase
        .from('keyword_weights')
        .select('keyword, weight')
        .eq('user_id', user.id)
        .order('weight', { ascending: false })
        .limit(100),
      // 3. í•™ìŠµëœ íšŒì‚¬ ì„ í˜¸ë„
      supabase
        .from('company_preference')
        .select('company_name, preference_score')
        .eq('user_id', user.id),
      // 4. ì´ë¯¸ ë³¸ ê³µê³  ID
      supabase
        .from('user_job_actions')
        .select('job_id')
        .eq('user_id', user.id),
    ])

    const preferences: UserPreferences | null = prefsResult.data
    const keywordWeights: KeywordWeight[] = keywordsResult.data || []
    const companyPrefs: CompanyPref[] = companiesResult.data || []
    const seenJobIds = new Set(seenResult.data?.map(a => a.job_id) || [])

    // 5. í™œì„± ê³µê³  ê°€ì ¸ì˜¤ê¸° (ë„‰ë„‰í•˜ê²Œ)
    const fetchLimit = (offset + limit) * 3 + 200
    const { data: jobs, error: jobsError } = await supabase
      .from('jobs')
      .select('*')
      .eq('is_active', true)
      .order('crawled_at', { ascending: false })
      .limit(fetchLimit)

    if (jobsError) {
      console.error('Jobs query error:', jobsError)
      return NextResponse.json({ error: 'Failed to fetch jobs' }, { status: 500 })
    }

    if (!jobs || jobs.length === 0) {
      return NextResponse.json({
        jobs: [],
        total: 0,
        limit,
        offset,
        message: 'No jobs available. Please run the crawler first.',
      })
    }

    // 6. ì´ë¯¸ ë³¸ ê³µê³  ì œì™¸ + ì ìˆ˜ ê³„ì‚° + í•„í„°ë§ + ì •ë ¬
    const now = Date.now()
    const scoredJobs = jobs
      .filter((job: JobRow) => !seenJobIds.has(job.id))
      .map((job: JobRow) => {
        const { score, reasons, warnings, matchesFilter } = scoreJob(job, preferences, keywordWeights, companyPrefs)
        const isNew = (now - new Date(job.crawled_at).getTime()) < 24 * 60 * 60 * 1000

        return {
          id: job.id,
          company: job.company,
          company_image: job.company_image,
          title: job.title,
          location: job.location || 'ìœ„ì¹˜ ë¯¸ì •',
          score,
          reason: reasons[0] || 'ì¶”ì²œ ê³µê³ ',
          reasons,
          warnings,
          link: `https://zighang.com/recruitment/${job.id}`,
          source: job.source,
          crawledAt: job.crawled_at,
          detail: job.detail,
          depth_ones: job.depth_ones,
          depth_twos: job.depth_twos,
          keywords: job.keywords,
          career_min: job.career_min,
          career_max: job.career_max,
          employee_types: job.employee_types,
          deadline_type: job.deadline_type,
          end_date: job.end_date,
          is_new: isNew,
          matchesFilter,
        }
      })
      .filter(j => j.matchesFilter) // í•„í„° í†µê³¼í•œ ê³µê³ ë§Œ
      .sort((a, b) => {
        if (b.score !== a.score) return b.score - a.score
        return new Date(b.crawledAt).getTime() - new Date(a.crawledAt).getTime()
      })

    // 7. 40ì  ì´ìƒ í•„í„° + í˜ì´ì§€ë„¤ì´ì…˜
    const passedJobs = scoredJobs.filter(j => j.score >= 40)
    const paginatedJobs = passedJobs.slice(offset, offset + limit)

    return NextResponse.json({
      jobs: paginatedJobs,
      total: passedJobs.length,
      limit,
      offset,
      hasMore: offset + limit < passedJobs.length,
    })

  } catch (error) {
    console.error('Error fetching jobs:', error)
    return NextResponse.json(
      { error: 'Failed to fetch jobs' },
      { status: 500 }
    )
  }
}
